var documenterSearchIndex = {"docs":
[{"location":"API/MarkovChainMonteCarlo/#Utilities","page":"MarkovChainMonteCarlo","title":"Utilities","text":"","category":"section"},{"location":"API/MarkovChainMonteCarlo/","page":"MarkovChainMonteCarlo","title":"MarkovChainMonteCarlo","text":"CurrentModule = CalibrateEmulateSample.MarkovChainMonteCarlo","category":"page"},{"location":"API/MarkovChainMonteCarlo/","page":"MarkovChainMonteCarlo","title":"MarkovChainMonteCarlo","text":"MCMC","category":"page"},{"location":"API/MarkovChainMonteCarlo/#CalibrateEmulateSample.MarkovChainMonteCarlo.MCMC","page":"MarkovChainMonteCarlo","title":"CalibrateEmulateSample.MarkovChainMonteCarlo.MCMC","text":"MCMC{FT<:AbstractFloat, IT<:Int}\n\nStructure to organize MCMC parameters and data\n\nFields\n\nobs_sample\na single sample from the observations. Can e.g. be picked from an Observation struct using getobssample\nobs_noise_cov\ncovariance of the observational noise\nprior\narray of length N_parameters with the parameters' prior distributions\nstep\nMCMC step size\nburnin\nNumber of MCMC steps that are considered burnin\nparam\nthe current parameters\nposterior\nArray of accepted MCMC parameter samples. The histogram of these samples gives an approximation of the posterior distribution of the parameters. paramdim x nsamples\nlog_posterior\nthe (current) value of the logarithm of the posterior (= loglikelihood + logprior of the current parameters)\niter\niteration/step of the MCMC\naccept\nnumber of accepted proposals\nalgtype\nMCMC algorithm to use - currently implemented: 'rwm' (random walk Metropolis), 'pCN' (preconditioned Crank-Nicholson)\nrng\nRandom number generator object (algorithm + seed) used for sampling and noise, for reproducibility.\n\n\n\n\n\n","category":"type"},{"location":"examples/lorenz_example/#Lorenz-96-example","page":"Lorenz example","title":"Lorenz 96 example","text":"","category":"section"},{"location":"examples/lorenz_example/","page":"Lorenz example","title":"Lorenz example","text":"We provide the following template for how the tools may be applied.","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz example","title":"Lorenz example","text":"For small examples typically have 2 files.","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz example","title":"Lorenz example","text":"GModel.jl Contains the forward map. The inputs should be the so-called free parameters we are interested in learning, and the output should be the measured data\nThe example script which contains the inverse problem setup and solve","category":"page"},{"location":"examples/lorenz_example/#The-structure-of-the-example-script","page":"Lorenz example","title":"The structure of the example script","text":"","category":"section"},{"location":"examples/lorenz_example/","page":"Lorenz example","title":"Lorenz example","text":"First we create the data and the setting for the model","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz example","title":"Lorenz example","text":"Set up the forward model.\nConstruct/load the truth data. Store this data conveniently in the Observations.Observation object","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz example","title":"Lorenz example","text":"Then we set up the inverse problem","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz example","title":"Lorenz example","text":"Define the prior distributions. Use the ParameterDistribution object\nDecide on which process tool you would like to use (we recommend you begin with Invesion()). Then initialize this with the relevant constructor\ninitialize the EnsembleKalmanProcess object","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz example","title":"Lorenz example","text":"Then we solve the inverse problem, in a loop perform the following for as many iterations as required:","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz example","title":"Lorenz example","text":"Obtain the current parameter ensemble\nTransform them from the unbounded computational space to the physical space\ncall the forward map on the ensemble of parameters, producing an ensemble of measured data\ncall the update_ensemble! function to generate a new parameter ensemble based on the new data","category":"page"},{"location":"examples/lorenz_example/","page":"Lorenz example","title":"Lorenz example","text":"One can then obtain the solution, dependent on the process type.","category":"page"},{"location":"API/GaussianProcess/#GaussianProcess","page":"Gaussian Process","title":"GaussianProcess","text":"","category":"section"},{"location":"API/GaussianProcess/","page":"Gaussian Process","title":"Gaussian Process","text":"CurrentModule = CalibrateEmulateSample.Emulators","category":"page"},{"location":"API/GaussianProcess/","page":"Gaussian Process","title":"Gaussian Process","text":"GaussianProcessesPackage\nPredictionType\nGaussianProcess\nbuild_models!\noptimize_hyperparameters!(::GaussianProcess{GPJL})","category":"page"},{"location":"API/GaussianProcess/#CalibrateEmulateSample.Emulators.GaussianProcessesPackage","page":"Gaussian Process","title":"CalibrateEmulateSample.Emulators.GaussianProcessesPackage","text":"GaussianProcessesPackage\n\nType to dispatch which GP package to use\n\nGPJL for GaussianProcesses.jl,\nSKLJL for the ScikitLearn GaussianProcessRegressor\n\n\n\n\n\n","category":"type"},{"location":"API/GaussianProcess/#CalibrateEmulateSample.Emulators.PredictionType","page":"Gaussian Process","title":"CalibrateEmulateSample.Emulators.PredictionType","text":"PredictionType\n\nPredict type for GPJL in GaussianProcesses.jl\n\nYType\nFType latent function\n\n\n\n\n\n","category":"type"},{"location":"API/GaussianProcess/#CalibrateEmulateSample.Emulators.GaussianProcess","page":"Gaussian Process","title":"CalibrateEmulateSample.Emulators.GaussianProcess","text":"GaussianProcess{FT<:AbstractFloat} <: MachineLearningTool\n\nStructure holding training input and the fitted Gaussian Process Regression\n\nmodels.\n\nFields\n\nmodels\nthe Gaussian Process (GP) Regression model(s) that are fitted to the given input-data pairs\nkernel\nKernel object\nnoise_learn\nlearn the noise with the White Noise kernel explicitly?\nprediction_type\nprediction type (y to predict the data, f to predict the latent function)\n\n\n\n\n\n","category":"type"},{"location":"API/GaussianProcess/#CalibrateEmulateSample.Emulators.build_models!","page":"Gaussian Process","title":"CalibrateEmulateSample.Emulators.build_models!","text":"function build_models!(\n    gp::GaussianProcess{package},\n    input_output_pairs)\n\nmethod to build gaussian process models based on the package\n\n\n\n\n\n","category":"function"},{"location":"API/GaussianProcess/#CalibrateEmulateSample.Emulators.optimize_hyperparameters!-Tuple{CalibrateEmulateSample.Emulators.GaussianProcess{CalibrateEmulateSample.Emulators.GPJL}}","page":"Gaussian Process","title":"CalibrateEmulateSample.Emulators.optimize_hyperparameters!","text":"function optimize_hyperparameters!(gp::GaussianProcess{package})\n\noptimize Gaussian Process hyperparameters using in-build package method\n\n\n\n\n\n","category":"method"},{"location":"API/Emulators/#Emulators","page":"General Emulator","title":"Emulators","text":"","category":"section"},{"location":"API/Emulators/","page":"General Emulator","title":"General Emulator","text":"CurrentModule = CalibrateEmulateSample.Emulators","category":"page"},{"location":"API/Emulators/","page":"General Emulator","title":"General Emulator","text":"Decomposition\nEmulator\noptimize_hyperparameters!(::Emulator)\npredict\nnormalize\nstandardize\nreverse_standardize\nsvd_transform\nsvd_reverse_transform_mean_cov","category":"page"},{"location":"API/Emulators/#CalibrateEmulateSample.Emulators.Decomposition","page":"General Emulator","title":"CalibrateEmulateSample.Emulators.Decomposition","text":"Decomposition{<:AbstractFloat, <:Int}\n\nStruct of SVD decomposition, containing (V,S,Vt), and the size of S, N. \n\n\n\n\n\n","category":"type"},{"location":"API/Emulators/#CalibrateEmulateSample.Emulators.Emulator","page":"General Emulator","title":"CalibrateEmulateSample.Emulators.Emulator","text":"Emulator\n\nStructure used to represent a general emulator:\n\n\n\n\n\n","category":"type"},{"location":"API/Emulators/#CalibrateEmulateSample.Emulators.optimize_hyperparameters!-Tuple{CalibrateEmulateSample.Emulators.Emulator}","page":"General Emulator","title":"CalibrateEmulateSample.Emulators.optimize_hyperparameters!","text":"function optimize_hyperparameters!(emulator::Emulator)\n\noptimize the hyperparameters in the machine learning tool\n\n\n\n\n\n","category":"method"},{"location":"API/Emulators/#CalibrateEmulateSample.Emulators.predict","page":"General Emulator","title":"CalibrateEmulateSample.Emulators.predict","text":"function predict(gp::GaussianProcess{package}, new_inputs::Array{FT, 2})\n\npredict means and covariances in decorrelated output space using gaussian process models\n\n\n\n\n\nfunction predict(emulator::Emulator, new_inputs; transform_to_real=false)\n\nmakes a prediction using the emulator on new inputs (each new inputs given as data columns), default is to predict in the decorrelated space\n\n\n\n\n\n","category":"function"},{"location":"API/Emulators/#CalibrateEmulateSample.Emulators.normalize","page":"General Emulator","title":"CalibrateEmulateSample.Emulators.normalize","text":"function normalize(emulator::Emulator, inputs)\n\nnormalize the input data, with a normalizing function\n\n\n\n\n\nfunction normalize(inputs, input_mean, sqrt_inv_input_cov)\n\nnormalize with the empirical Gaussian distribution of points\n\n\n\n\n\n","category":"function"},{"location":"API/Emulators/#CalibrateEmulateSample.Emulators.standardize","page":"General Emulator","title":"CalibrateEmulateSample.Emulators.standardize","text":"function standardize(outputs, output_cov, factors)\n\nstandardize with a vector of factors (size equal to output dimension)\n\n\n\n\n\n","category":"function"},{"location":"API/Emulators/#CalibrateEmulateSample.Emulators.reverse_standardize","page":"General Emulator","title":"CalibrateEmulateSample.Emulators.reverse_standardize","text":"function reverse_standardize(emulator::Emulator, outputs, output_cov)\n\nreverse a previous standardization with the stored vector of factors (size equal to output dimension)\n\n\n\n\n\n","category":"function"},{"location":"API/Emulators/#CalibrateEmulateSample.Emulators.svd_transform","page":"General Emulator","title":"CalibrateEmulateSample.Emulators.svd_transform","text":"svdtransform(data::Array{FT, 2}, obsnoise_cov::Union{Array{FT, 2}, Nothing}) where {FT}\n\nApply a singular value decomposition (SVD) to the data\n\ndata - GP training data/targets; outputdim × Nsamples\nobs_noise_cov - covariance of observational noise\n\nReturns the transformed data and the decomposition, which is a matrix  factorization of type LinearAlgebra.SVD. \n\nNote: If F::SVD is the factorization object, U, S, V and Vt can be obtained via  F.U, F.S, F.V and F.Vt, such that A = U * Diagonal(S) * Vt. The singular values  in S are sorted in descending order.\n\n\n\n\n\nfunction svdtransform(     data::Vector{FT},      obsnoisecov::Union{Array{FT, 2}, Nothing};     truncatesvd::FT=1.0) where {FT}\n\n\n\n\n\n","category":"function"},{"location":"API/Emulators/#CalibrateEmulateSample.Emulators.svd_reverse_transform_mean_cov","page":"General Emulator","title":"CalibrateEmulateSample.Emulators.svd_reverse_transform_mean_cov","text":"svdreversetransformmeancov(μ::Array{FT, 2}, σ2::{Array{FT, 2}, decomposition::SVD) where {FT}\n\nTransform the mean and covariance back to the original (correlated) coordinate system\n\nμ - predicted mean; outputdim × Npredicted_points\nσ2 - predicted variance; outputdim × Npredicted_points \n\nReturns the transformed mean (outputdim × Npredictedpoints) and variance.  Note that transforming the variance back to the original coordinate system results in non-zero off-diagonal elements, so instead of just returning the  elements on the main diagonal (i.e., the variances), we return the full  covariance at each point, as a vector of length Npredictedpoints, where  each element is a matrix of size outputdim × output_dim\n\n\n\n\n\n","category":"function"},{"location":"#CalibrateEmulateSample.jl","page":"Home","title":"CalibrateEmulateSample.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"CalibrateEmulateSample.jl solves parameter estimation problems using (approximate) Bayesian inversion. It is designed for problems that require running a computer model that is expensive to evaluate, but can also be used for simple models.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The computer model is supplied by the user – it is a forward model, i.e., it takes certain parameters and produces data that can then be compared with the actual observations. We can think of that model as a parameter-to-data map G(u) mathbbR^p rightarrow mathbbR^d. For example, G could be a global climate model or a model that predicts the motion of a robot arm. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"The data produced by the forward model are compared to observations y, which are assumed to be corrupted by additive noise eta, such that","category":"page"},{"location":"","page":"Home","title":"Home","text":"beginequation\ny = G(u) + eta\nendequation","category":"page"},{"location":"","page":"Home","title":"Home","text":"where the noise eta is drawn from a d-dimensional Gaussian with distribution mathcalN(0 Gamma_y).","category":"page"},{"location":"","page":"Home","title":"Home","text":"Given knowledge of the  observations y, the forward model G(u) mathbbR^p rightarrow mathbbR^d, and some information about the noise level such as its size or distribution (but not its value), the inverse problem we want to solve is to find the unknown parameters u.","category":"page"},{"location":"","page":"Home","title":"Home","text":"As the name suggests, CalibrateEmulateSample.jl breaks this problem into a sequence of three steps: calibration, emulation, and sampling. A comprehensive treatment of the calibrate-emulate-sample approach to Bayesian inverse problems can be found in Cleary et al., 2020.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In a one-sentence summary, the calibrate step of the algorithm consists of an Ensemble Kalman inversion that is used to find good training points for a Gaussian process regression, which in turn is used as a surrogate (emulator) of the original forward model G in the subsequent Markov chain Monte Carlo sampling of the posterior distributions of the unknown parameters.","category":"page"},{"location":"","page":"Home","title":"Home","text":"CalibrateEmulateSample.jl contains the following modules:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Module Purpose\nEnsembleKalmanProcesses.jl Calibrate – Ensemble Kalman inversion\nGaussianProcessEmulator.jl Emulate – Gaussian process regression\nMarkovChainMonteCarlo.jl Sample – Markov chain Monte Carlo\nObservations.jl Structure to hold observations\nUtilities.jl Helper functions","category":"page"},{"location":"","page":"Home","title":"Home","text":"The best way to get started is to have a look at the examples!","category":"page"},{"location":"installation_instructions/#Installation-Instructions","page":"Installation instructions","title":"Installation Instructions","text":"","category":"section"},{"location":"installation_instructions/#Installing-CalibrateEmulateSample.jl","page":"Installation instructions","title":"Installing CalibrateEmulateSample.jl","text":"","category":"section"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"Currently CalibrateEmulateSample (CES) depends on some external python dependencies including scikit-learn wrapped by ScikitLearn.jl which requires a couple extra installation steps:","category":"page"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"First clone the project into a new local repository","category":"page"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"> git clone git@github.com:Clima/CalibrateEmulateSample.jl\n> cd CalibrateEmulateSample.jl","category":"page"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"Install and build the project dependencies.   Given that CES depends on python packages it is easiest to set the project to use it's own Conda environment variable (set by exporting the ENV variable PYTHON=\"\").","category":"page"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"> PYTHON=\"\" julia --project -e 'using Pkg; Pkg.instantiate()","category":"page"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"The scikit-learn package then has to be installed if using a Julia project specific Conda environment:","category":"page"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"> PYTHON=\"\" julia --project= -e 'using Conda; Conda.add(\"scikit-learn\")'\n","category":"page"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"See the PyCall.jl documentation  for more information about how to configure the local Julia / Conda / Python environment.","category":"page"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"To test that the package is working:","category":"page"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"> julia --project -e 'using Pkg; Pkg.test()'","category":"page"},{"location":"installation_instructions/#Building-the-documentation-locally","page":"Installation instructions","title":"Building the documentation locally","text":"","category":"section"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"You need to first build the top-level project before building the documentation:","category":"page"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"cd CalibrateEmulateSample.jl\njulia --project -e 'using Pkg; Pkg.instantiate()","category":"page"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"Then you can build the project documentation under the docs/ sub-project:","category":"page"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"julia --project=docs/ -e 'using Pkg; Pkg.instantiate()'\njulia --project=docs/ docs/make.jl","category":"page"},{"location":"installation_instructions/","page":"Installation instructions","title":"Installation instructions","text":"The locally rendered HTML documentation can be viewed at docs/build/index.html","category":"page"}]
}
