{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  \n",
    "## Calibrate-Emulate-Sample Demo: Application to a Cloud Microphysics Toy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how parameters of cloud droplet size distributions can be learned from data generated by Cloudy, a cloud microphysics toy model that can be downloaded here: https://github.com/climate-machine/Cloudy.jl. \n",
    "\n",
    "Cloudy takes the following input:\n",
    "* parameters defining a **cloud droplet size distribution** (e.g., parameters defining a gamma distribution or an exponential distribution)\n",
    "* a **''kernel''** defining the efficiency with which cloud droplets collide and coalesce (i.e., stick together and form bigger droplets). \n",
    "\n",
    "Cloudy then simulates how the cloud droplet size distribution evolves over time as a result of the droplet interactions defined by the given kernel. It does so by computing a (user-defined) number of moments of the distribution and propagating them forward in time. The simulation stops after a user-defined amount of time $T$. \n",
    "Treating the kernel as given, Cloudy can be viewed as a function $G(\\theta): \\mathbb{R}^p \\rightarrow \\mathbb{R}^d$ that maps the vector of parameters describing the initial droplet distribution, $\\theta = [\\theta_1, \\theta_2, \\ldots, \\theta_p]$, to a vector of moments, $M = [M_0^T, M_1^T, \\ldots, M_d^T]$\n",
    "\n",
    "The model equation assumes that we have observations $y$ of the moments coming from some observing system, and that these observations are corrupted by additive noise $\\eta$ such that\n",
    "\\begin{equation}\n",
    "    y = G(\\theta) + \\eta,\n",
    "\\end{equation}\n",
    "\n",
    "where the noise $\\theta$ is drawn from a d-dimensional Gaussian with distribution $N(0, \\Gamma_y)$.\n",
    "\n",
    "In this demo, we test the calibrate-emulate-sample framework in a **''perfect-model'' setting**, which means that the observations $y$ do not come from some external observing system but are generated by running Cloudy with the  parameters set to their ''true'' values. \n",
    "\n",
    "**Given knowledge of the artificial observations $y$, the forward model $G: \\mathbb{R}^p \\rightarrow \\mathbb{R}^d$, and some information about the noise level such as its size or distribution (but not its value), the inverse problem we want to solve is to find the unknown parameters $\\theta$.**\n",
    "\n",
    "A comprehensive treatment of the calibrate-emulate-sample approach to Bayesian inverse problems can be found in Cleary et al., 2020: https://arxiv.org/pdf/2001.03689.pdf\n",
    "\n",
    "In a one-sentence summary, the **calibrate** step of the algorithm consists of an Ensemble Kalman Inversion that is used to find good training points for a Gaussian process regression, which in turn is used as a replacement (**emulator**) of the original forward model $G$ in the subsequent Markov chain Monte Carlo **sampling** of the posterior distributions of the unknown parameters.\n",
    "\n",
    "**Final remarks**: Calibrate-emulate-sample was developed to solve inverse problems in situations when running the forward model $G$ is computationally expensive. Cloudy is very cheap to run and it would be computationally feasible to skip the ''calibrate'' and ''emulate'' steps, but this being a demo, we will walk the user through the full pipeline. Applying the full pipeline may also improve the result even when it's not necessary for computational reasons, e.g., because the Gaussian process regression smooths the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cloudy_model.jpg\" alt=\"Cloudy\" style=\"width:600px\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Cloudy modules\n",
    "using Cloudy.KernelTensors\n",
    "using Cloudy.PDistributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "using JLD2 # saving and loading Julia arrays\n",
    "using Distributions  # probability distributions and associated functions \n",
    "using StatsBase\n",
    "using LinearAlgebra\n",
    "using StatsPlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.MCMC"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Calibrate-Emulate-Sample modules (adjust paths \n",
    "# if necessary)\n",
    "include(\"CalibrateEmulateSample.jl/src/EKI.jl\")\n",
    "include(\"CalibrateEmulateSample.jl/src/Truth.jl\")\n",
    "include(\"CalibrateEmulateSample.jl/src/GPEmulator.jl\")\n",
    "include(\"CalibrateEmulateSample.jl/src/MCMC.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the data from which we want to learn \n",
    "data_names = [\"M0\", \"M1\", \"M2\"]\n",
    "moments = [0.0, 1.0, 2.0]\n",
    "n_moments = length(moments)\n",
    "param_names = [\"N0\", \"θ\", \"k\"]\n",
    "\n",
    "FT = Float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.Truth.TruthObj(Cloudy.PDistributions.Gamma{Float64}(3650.0, 4.1, 2.0), retcode: Success\n",
       "Interpolation: 3rd order Hermite\n",
       "t: [0.0, 1.43246e-6, 2.86492e-6, 6.77977e-6, 1.06946e-5, 1.46095e-5, 1.85243e-5, 2.65758e-5, 4.23722e-5, 7.43235e-5  …  0.407798, 0.415624, 0.42345, 0.431276, 0.443082, 0.454888, 0.466694, 0.4785, 0.490306, 0.5]\n",
       "u: Array{Float64,1}[[3650.0, 29930.0, 368139.0], [3649.24, 29930.0, 3.68241e5], [3648.48, 29930.0, 3.68343e5], [3646.41, 29930.0, 3.68623e5], [3644.34, 29930.0, 3.68902e5], [3642.27, 29930.0, 369181.0], [3640.2, 29930.0, 3.6946e5], [3635.96, 29930.0, 3.70034e5], [3627.67, 29930.0, 3.71161e5], [3611.0, 29930.0, 3.7344e5]  …  [60.5768, 29930.0, 2.94531e7], [59.4548, 29930.0, 3.00113e7], [58.3736, 29930.0, 3.05695e7], [57.3309, 29930.0, 3.11276e7], [55.8267, 29930.0, 3.19697e7], [54.3994, 29930.0, 3.28117e7], [53.0432, 29930.0, 3.36537e7], [51.753, 29930.0, 3.44958e7], [50.5241, 29930.0, 3.53378e7], [49.5579, 29930.0, 3.60292e7]], [49.5579, 29930.0, 3.60292e7], [7.40574 -6.82956 -8.63348; -6.82956 6.53669 8.88536; -8.63348 8.88536 21.557], [\"M0\", \"M1\", \"M2\"])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the true parameters and distribution as well as the\n",
    "# priors of the parameters\n",
    "N0_true = 3650.\n",
    "θ_true = 4.1\n",
    "k_true = 2.0\n",
    "priors = [Distributions.Normal(3000., 500.), # prior on N0\n",
    "          Distributions.Normal(6.0, 2.0),    # prior on θ\n",
    "          Distributions.Normal(3.0, 1.5)]    # prior on k \n",
    "\n",
    "# We assume that the true particle mass distribution is a \n",
    "# Gamma distribution with parameters N0_true, θ_true, k_true\n",
    "# Note that dist_true has to be a Cloudy distribution, not a \n",
    "# \"regular\" Julia distribution\n",
    "dist_true = PDistributions.Gamma(N0_true, θ_true, k_true)\n",
    "\n",
    "# Collision-coalescence kernel to be used in Cloudy\n",
    "coalescence_coeff = 1/3.14/4\n",
    "kernel = ConstantCoalescenceTensor(coalescence_coeff)\n",
    "\n",
    "# Time period over which to run Cloudy\n",
    "tspan = (0., 0.5)  \n",
    "\n",
    "# Generate the truth (a Truth.TruthObj)\n",
    "truth = Truth.run_cloudy_truth(kernel, dist_true, moments, \n",
    "                               tspan, data_names, nothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrate: Ensemble Kalman Inversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exp_transform (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_transform(a::AbstractArray) = log.(a)\n",
    "exp_transform(a::AbstractArray) = exp.(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.EKI.EKIObj(Array{Float64,2}[[8.22474 1.87038 1.11537; 8.04893 1.27945 1.53624; … ; 8.01486 0.57864 1.42383; 8.11053 2.07088 1.49046]], [\"N0\", \"θ\", \"k\"], [49.5579, 29930.0, 3.60292e7], [7.40574 -6.82956 -8.63348; -6.82956 6.53669 8.88536; -8.63348 8.88536 21.557], 50, Array{Float64,2}[], Float64[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_ens = 50 # number of ensemble members\n",
    "N_iter = 5 # number of EKI iterations\n",
    "# initial parameters: N_ens x N_params\n",
    "initial_params = EKI.construct_initial_ensemble(N_ens, priors; rng_seed=5)\n",
    "# Note: For the model G (=Cloudy) to run, N0 needs to be \n",
    "# nonnegative, and θ and k need to be positive. \n",
    "# The EKI update can result in violations of these constraints - \n",
    "# therefore, we log-transform the initial ensemble, perform all \n",
    "# EKI operations in log space and run G with the exponentiated \n",
    "# parameters, which ensures positivity.\n",
    "ekiobj = EKI.EKIObj(log_transform(initial_params), \n",
    "                    param_names, truth.y_t, truth.cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cloudy.PDistributions.Gamma{Float64}(1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a CDistribution with dummy parameters\n",
    "# The parameters will then be set in run_cloudy_ensemble\n",
    "dummy = 1.0\n",
    "dist_type = PDistributions.Gamma(dummy, dummy, dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EKI iterations\n",
    "for i in 1:N_iter\n",
    "    # Note the exp-transform to ensure positivity of the \n",
    "    # parameters\n",
    "    g_ens = EKI.run_cloudy_ensemble(kernel, dist_type, \n",
    "                                    exp_transform(ekiobj.u[end]), \n",
    "                                    moments, tspan)\n",
    "    EKI.update_ensemble!(ekiobj, g_ens) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True parameters: \n",
      "(Symbol[:n, :θ, :k], [3650.0, 4.1, 2.0])\n",
      "\n",
      "EKI results:\n",
      "[3489.06 3.63165 2.56231]\n"
     ]
    }
   ],
   "source": [
    "# EKI results: Has the ensemble collapsed toward the truth?\n",
    "true_params = PDistributions.get_params(truth.distr_init)\n",
    "println(\"True parameters: \")\n",
    "println(true_params)\n",
    "\n",
    "println(\"\\nEKI results:\")\n",
    "println(mean(exp_transform(ekiobj.u[end]), dims=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the evolution of the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Plots\n",
    "gr()\n",
    "\n",
    "p = plot(exp_transform(ekiobj.u[1][:, 2]), \n",
    "         exp_transform(ekiobj.u[1][:, 3]), \n",
    "         seriestype=:scatter)\n",
    "for i in 2:N_iter\n",
    "    plot!(exp_transform(ekiobj.u[i][:, 2]), \n",
    "          exp_transform(ekiobj.u[i][:, 3]), \n",
    "          seriestype=:scatter)\n",
    "end\n",
    "\n",
    "plot!([θ_true], xaxis=\"theta\", yaxis=\"k\", seriestype=\"vline\", \n",
    "      linestyle=:dash, linecolor=:red)\n",
    "plot!([k_true], seriestype=\"hline\", linestyle=:dash, linecolor=:red)\n",
    "\n",
    "\n",
    "savefig(p, \"EKI_test.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulate: Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250×3 Array{Float64,2}:\n",
       " 3732.15  6.49075  3.0507  \n",
       " 3130.44  3.59465  4.64708 \n",
       " 2875.78  5.89844  2.92272 \n",
       " 3567.06  4.52769  2.40578 \n",
       " 2212.71  4.01028  3.96531 \n",
       " 2550.05  5.44463  2.87062 \n",
       " 2718.09  5.11     3.74886 \n",
       " 2486.02  7.95535  1.62365 \n",
       " 2967.69  4.41036  5.22889 \n",
       " 3203.76  7.69733  2.23254 \n",
       " 3706.09  3.11064  0.967374\n",
       " 3331.03  4.65329  2.39967 \n",
       " 2844.38  7.57895  5.26408 \n",
       "    ⋮                      \n",
       " 3207.32  2.96297  3.14941 \n",
       " 3234.34  2.92603  3.16273 \n",
       " 3894.72  4.62297  1.6623  \n",
       " 3101.99  2.5645   3.76234 \n",
       " 3548.0   3.89275  2.16701 \n",
       " 3479.21  3.7053   2.32164 \n",
       " 3090.54  2.6212   3.69462 \n",
       " 3981.27  4.7643   1.57794 \n",
       " 3507.62  3.69074  2.31202 \n",
       " 3628.6   4.00773  2.05815 \n",
       " 2870.45  1.94426  5.36293 \n",
       " 3489.85  3.72149  2.30451 "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gppackage = \"gp_jl\"\n",
    "yt, yt_cov, yt_covinv, log_u_tp, g_tp = GPEmulator.extract(truth, ekiobj, N_iter)\n",
    "u_tp = exp_transform(log_u_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250×3 Array{Float64,2}:\n",
       "  1.46431     0.245375    0.0338007\n",
       "  0.260871   -1.20267     1.09805  \n",
       " -0.248434   -0.0507798  -0.0515193\n",
       "  1.13412    -0.736155   -0.396147 \n",
       " -1.57459    -0.994859    0.643538 \n",
       " -0.899893   -0.277684   -0.0862517\n",
       " -0.563828   -0.445       0.499241 \n",
       " -1.02797     0.977675   -0.917568 \n",
       " -0.0646294  -0.79482     1.48593  \n",
       "  0.407523    0.848664   -0.51164  \n",
       "  1.41217    -1.44468    -1.35508  \n",
       "  0.662051   -0.673357   -0.400219 \n",
       " -0.311238    0.789473    1.50939  \n",
       "  ⋮                                \n",
       "  0.414639   -1.51852     0.0996054\n",
       "  0.46867    -1.53698     0.108484 \n",
       "  1.78943    -0.688515   -0.8918   \n",
       "  0.203986   -1.71775     0.508223 \n",
       "  1.09601    -1.05362    -0.555325 \n",
       "  0.958425   -1.14735    -0.452243 \n",
       "  0.181087   -1.6894      0.46308  \n",
       "  1.96253    -0.617849   -0.948042 \n",
       "  1.01524    -1.15463    -0.458654 \n",
       "  1.2572     -0.996134   -0.627901 \n",
       " -0.259107   -2.02787     1.57529  \n",
       "  0.979695   -1.13925    -0.463659 "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize both the data and the parameters\n",
    "data_mean = vec(mean(g_tp, dims=1))\n",
    "data_std = vec(std(g_tp, dims=1))\n",
    "g_tp_zscore = GPEmulator.orig2zscore(g_tp, data_mean, data_std)\n",
    "\n",
    "param_mean = [mean(prior) for prior in priors]\n",
    "param_std = [std(prior) for prior in priors]\n",
    "u_tp_zscore = GPEmulator.orig2zscore(u_tp, param_mean, param_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.GPEmulator.GPObj([1.46431 0.260871 … -0.259107 0.979695; 0.245375 -1.20267 … -2.02787 -1.13925; 0.0338007 1.09805 … 1.57529 -0.463659], [1.00958 0.107934 … -0.396564 0.68338; 2.25359 1.02854 … -0.239267 -0.23928; 1.75654 0.554677 … -0.256791 -0.256822], Any[GP Exact object:\n",
       "  Dim = 3\n",
       "  Number of observations = 250\n",
       "  Mean function:\n",
       "    Type: MeanZero, Params: Float64[]\n",
       "  Kernel:\n",
       "    Type: GaussianProcesses.SumKernel{GaussianProcesses.SumKernel{GaussianProcesses.SEIso{Float64},GaussianProcesses.Mat52Ard{Float64}},GaussianProcesses.Noise{Float64}}\n",
       "      Type: GaussianProcesses.SumKernel{GaussianProcesses.SEIso{Float64},GaussianProcesses.Mat52Ard{Float64}}\n",
       "        Type: SEIso{Float64}, Params: [1.46901, 1.04661]        Type: Mat52Ard{Float64}, Params: [12.0182, 9.21207, 10.4125, -16.3933]      Type: Noise{Float64}, Params: [-56.2467]\n",
       "  Input observations = \n",
       "[1.46431 0.260871 … -0.259107 0.979695; 0.245375 -1.20267 … -2.02787 -1.13925; 0.0338007 1.09805 … 1.57529 -0.463659]\n",
       "  Output observations = [1.00958, 0.107934, -0.385308, 0.792069, -2.19056, -1.15705, -0.736256, -1.33209, -0.1977, 0.235646  …  1.20598, 0.056797, 0.765675, 0.668037, 0.035951, 1.30408, 0.708813, 0.875427, -0.396564, 0.68338]\n",
       "  Variance of observation noise = 5.70948e-51\n",
       "  Marginal Log-Likelihood = 1019.23, GP Exact object:\n",
       "  Dim = 3\n",
       "  Number of observations = 250\n",
       "  Mean function:\n",
       "    Type: MeanZero, Params: Float64[]\n",
       "  Kernel:\n",
       "    Type: GaussianProcesses.SumKernel{GaussianProcesses.SumKernel{GaussianProcesses.SEIso{Float64},GaussianProcesses.Mat52Ard{Float64}},GaussianProcesses.Noise{Float64}}\n",
       "      Type: GaussianProcesses.SumKernel{GaussianProcesses.SEIso{Float64},GaussianProcesses.Mat52Ard{Float64}}\n",
       "        Type: SEIso{Float64}, Params: [1.39015, 1.06525]        Type: Mat52Ard{Float64}, Params: [2.78306, 1.78856, 1.94862, -3.97399]      Type: Noise{Float64}, Params: [-26.8074]\n",
       "  Input observations = \n",
       "[1.46431 0.260871 … -0.259107 0.979695; 0.245375 -1.20267 … -2.02787 -1.13925; 0.0338007 1.09805 … 1.57529 -0.463659]\n",
       "  Output observations = [2.25359, 1.02854, 0.874573, 0.266695, 0.0587373, 0.323466, 1.01588, -0.115611, 1.94388, 1.18515  …  -0.239263, -0.239283, -0.239279, -0.239297, -0.23927, -0.239249, -0.23922, -0.239232, -0.239267, -0.23928]\n",
       "  Variance of observation noise = 1.12522e-24\n",
       "  Marginal Log-Likelihood = 1012.65, GP Exact object:\n",
       "  Dim = 3\n",
       "  Number of observations = 250\n",
       "  Mean function:\n",
       "    Type: MeanZero, Params: Float64[]\n",
       "  Kernel:\n",
       "    Type: GaussianProcesses.SumKernel{GaussianProcesses.SumKernel{GaussianProcesses.SEIso{Float64},GaussianProcesses.Mat52Ard{Float64}},GaussianProcesses.Noise{Float64}}\n",
       "      Type: GaussianProcesses.SumKernel{GaussianProcesses.SEIso{Float64},GaussianProcesses.Mat52Ard{Float64}}\n",
       "        Type: SEIso{Float64}, Params: [0.61198, 1.15894]        Type: Mat52Ard{Float64}, Params: [2.23869, 1.32188, 1.2152, -2.50146]      Type: Noise{Float64}, Params: [-21.7384]\n",
       "  Input observations = \n",
       "[1.46431 0.260871 … -0.259107 0.979695; 0.245375 -1.20267 … -2.02787 -1.13925; 0.0338007 1.09805 … 1.57529 -0.463659]\n",
       "  Output observations = [1.75654, 0.554677, 0.434666, 0.014105, -0.103519, 0.0512084, 0.546707, -0.194336, 1.41589, 0.687712  …  -0.256811, -0.256851, -0.256811, -0.256826, -0.256814, -0.256812, -0.256818, -0.256813, -0.256791, -0.256822]\n",
       "  Variance of observation noise = 3.79083e-20\n",
       "  Marginal Log-Likelihood = 1551.6], \"gp_jl\")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a Gaussian Process regression to the training points\n",
    "gpobj = GPEmulator.emulate(u_tp_zscore, g_tp_zscore, gppackage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP prediction on true parameters: \n",
      "[49.5579, 29931.0, 3.60292e7]\n",
      "true data: \n",
      "[49.5579, 29930.0, 3.60292e7]\n"
     ]
    }
   ],
   "source": [
    "# Check how well the Gaussian Process regression predicts on the\n",
    "# (standardized) true parameters\n",
    "u_true_zscore = GPEmulator.orig2zscore([N0_true θ_true k_true], \n",
    "                                        param_mean, param_std)\n",
    "\n",
    "y_mean, y_var = GPEmulator.predict(gpobj, reshape(u_true_zscore, 1, :))\n",
    "y_mean = cat(y_mean..., dims=2)\n",
    "y_var = cat(y_var..., dims=2)\n",
    "\n",
    "println(\"GP prediction on true parameters: \")\n",
    "println(vec(y_mean) .* data_std + data_mean)\n",
    "println(\"true data: \")\n",
    "println(truth.y_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample: Markov chain Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial parameters: [0.313805, -0.644657, -0.322028]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"rwm\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial values\n",
    "u0 = vec(mean(u_tp_zscore, dims=1))\n",
    "println(\"initial parameters: \", u0)\n",
    "\n",
    "# MCMC parameters    \n",
    "mcmc_alg = \"rwm\" # random walk Metropolis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       "  0.903768946851413  \n",
       " -0.23926255828549936\n",
       " -0.25681263301457585"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First let's run a short chain to determine a good step size\n",
    "burnin = 0\n",
    "step = 0.1 # first guess\n",
    "yt_zscore = GPEmulator.orig2zscore(yt, data_mean, data_std)\n",
    "#yt_cov_zscore = GPEmulator.orig2zscore(yt_cov, data_mean, data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin step size search\n",
      "iteration 0; current parameters [0.313805 -0.644657 -0.322028]\n",
      "iteration 2000; acceptance rate = 0.46476761619190404, current parameters [0.836495 -1.20015 -0.179453]\n",
      "new step size: 0.2\n",
      "iteration 2000; acceptance rate = 0.2383808095952024, current parameters [1.56049 0.0378608 -1.09249]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = 5000\n",
    "standardized = true # we are using z scores\n",
    "mcmc_test = MCMC.MCMCObj(yt_zscore, yt_cov./maximum(yt_cov), \n",
    "                        priors, step, u0, \n",
    "                        max_iter, mcmc_alg, burnin, standardized)\n",
    "new_step = MCMC.find_mcmc_step!(mcmc_test, gpobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin MCMC - with step size 0.2\n",
      "iteration 0; current parameters [1.20057 0.497962 -1.37575]\n",
      "iteration 1000 of 100000; acceptance rate = 0.27472527472527475, current parameters [0.61547 0.372809 -0.342979]\n",
      "iteration 2000 of 100000; acceptance rate = 0.26936531734132935, current parameters [1.28789 0.768395 -1.5862]\n",
      "iteration 3000 of 100000; acceptance rate = 0.2642452515828057, current parameters [1.93311 0.175259 -1.04231]\n",
      "iteration 4000 of 100000; acceptance rate = 0.25818545363659084, current parameters [0.22728 -1.08593 1.14468]\n",
      "iteration 5000 of 100000; acceptance rate = 0.2563487302539492, current parameters [1.5051 0.622083 -1.21323]\n",
      "iteration 6000 of 100000; acceptance rate = 0.25462422929511747, current parameters [0.75316 -1.52393 0.30652]\n",
      "iteration 7000 of 100000; acceptance rate = 0.257820311384088, current parameters [1.59974 -0.708183 -0.703053]\n",
      "iteration 8000 of 100000; acceptance rate = 0.25821772278465194, current parameters [1.30269 -1.84593 0.119875]\n",
      "iteration 9000 of 100000; acceptance rate = 0.2618597933562937, current parameters [0.542835 -0.6377 -0.182375]\n",
      "iteration 10000 of 100000; acceptance rate = 0.2592740725927407, current parameters [0.70864 -0.176608 -0.655689]\n",
      "iteration 11000 of 100000; acceptance rate = 0.25652213435142257, current parameters [1.11912 -1.10213 -0.399748]\n",
      "iteration 12000 of 100000; acceptance rate = 0.25822848095992, current parameters [0.902478 -1.04055 -0.722355]\n",
      "iteration 13000 of 100000; acceptance rate = 0.25890316129528496, current parameters [0.494274 -0.274224 -0.843858]\n",
      "iteration 14000 of 100000; acceptance rate = 0.25891007785158204, current parameters [0.932446 -0.261483 -0.916327]\n",
      "iteration 15000 of 100000; acceptance rate = 0.2596493567095527, current parameters [0.426027 -0.768619 -0.0646497]\n",
      "iteration 16000 of 100000; acceptance rate = 0.25973376663958503, current parameters [1.05065 -1.36938 -0.790961]\n",
      "iteration 17000 of 100000; acceptance rate = 0.2611611081701076, current parameters [1.08697 0.218156 -1.19053]\n",
      "iteration 18000 of 100000; acceptance rate = 0.2618187878451197, current parameters [1.38745 -0.360279 -0.684975]\n",
      "iteration 19000 of 100000; acceptance rate = 0.26214409767906954, current parameters [0.988688 -0.349049 -0.817287]\n",
      "iteration 20000 of 100000; acceptance rate = 0.26193690315484225, current parameters [0.740136 1.1711 -0.811189]\n",
      "iteration 21000 of 100000; acceptance rate = 0.26198752440359985, current parameters [1.4357 -0.100564 -1.23928]\n",
      "iteration 22000 of 100000; acceptance rate = 0.26021544475251124, current parameters [0.694722 -0.0785031 -1.2269]\n",
      "iteration 23000 of 100000; acceptance rate = 0.26064084170253465, current parameters [1.33793 0.307841 -1.18368]\n",
      "iteration 24000 of 100000; acceptance rate = 0.25957251781175783, current parameters [1.00988 0.412783 -1.21433]\n",
      "iteration 25000 of 100000; acceptance rate = 0.2601495940162393, current parameters [0.337498 0.09904 -0.716529]\n",
      "iteration 26000 of 100000; acceptance rate = 0.25979770008845815, current parameters [0.857282 -0.627351 -0.856011]\n",
      "iteration 27000 of 100000; acceptance rate = 0.25962001407355284, current parameters [0.0758354 0.0149657 -0.15548]\n",
      "iteration 28000 of 100000; acceptance rate = 0.259026463340595, current parameters [1.87252 -0.954027 -0.381993]\n",
      "iteration 29000 of 100000; acceptance rate = 0.2569566566670115, current parameters [1.22347 0.0300053 -1.03021]\n",
      "iteration 30000 of 100000; acceptance rate = 0.25779140695310154, current parameters [0.820282 -0.474922 -0.788579]\n",
      "iteration 31000 of 100000; acceptance rate = 0.2581529628076514, current parameters [1.47894 0.246951 -1.23435]\n",
      "iteration 32000 of 100000; acceptance rate = 0.25824192993968936, current parameters [1.35875 -0.0819225 -1.25534]\n",
      "iteration 33000 of 100000; acceptance rate = 0.2581739947274325, current parameters [0.240183 -0.281215 -0.441734]\n",
      "iteration 34000 of 100000; acceptance rate = 0.25722772859621773, current parameters [0.280736 0.27012 -0.987856]\n",
      "iteration 35000 of 100000; acceptance rate = 0.25667838061769666, current parameters [0.434686 0.189708 -0.462201]\n",
      "iteration 36000 of 100000; acceptance rate = 0.25713174634037944, current parameters [0.0763399 -0.54845 -0.489045]\n",
      "iteration 37000 of 100000; acceptance rate = 0.2565065809032188, current parameters [1.06904 0.272987 -0.586992]\n",
      "iteration 38000 of 100000; acceptance rate = 0.25638798978974237, current parameters [0.118894 1.10316 -0.341522]\n",
      "iteration 39000 of 100000; acceptance rate = 0.25630112048409015, current parameters [0.630244 -0.0405924 -1.05561]\n",
      "iteration 40000 of 100000; acceptance rate = 0.25656858578535535, current parameters [0.96458 -0.0551609 -0.714028]\n",
      "iteration 41000 of 100000; acceptance rate = 0.25655471817760545, current parameters [0.0592466 -1.05443 0.942342]\n",
      "iteration 42000 of 100000; acceptance rate = 0.2570653079688579, current parameters [0.633383 -1.22316 0.00493837]\n",
      "iteration 43000 of 100000; acceptance rate = 0.25662193902467384, current parameters [0.629421 -0.149059 -0.993144]\n",
      "iteration 44000 of 100000; acceptance rate = 0.2571759732733347, current parameters [1.86084 -1.99654 -0.00808412]\n",
      "iteration 45000 of 100000; acceptance rate = 0.25772760605319883, current parameters [0.751515 -0.486296 -0.231064]\n",
      "iteration 46000 of 100000; acceptance rate = 0.2574291863220365, current parameters [0.326703 0.597512 -0.936191]\n",
      "iteration 47000 of 100000; acceptance rate = 0.25720729346184124, current parameters [0.971003 -1.85273 0.378083]\n",
      "iteration 48000 of 100000; acceptance rate = 0.256848815649674, current parameters [0.461742 -0.556059 -0.427929]\n",
      "iteration 49000 of 100000; acceptance rate = 0.257015162955858, current parameters [1.50757 -1.37821 -0.196744]\n",
      "iteration 50000 of 100000; acceptance rate = 0.2570548589028219, current parameters [0.710413 -0.3474 -0.607879]\n",
      "iteration 51000 of 100000; acceptance rate = 0.25770082939550204, current parameters [0.227916 -1.04642 0.426461]\n",
      "iteration 52000 of 100000; acceptance rate = 0.25755273937039674, current parameters [1.35168 -0.146709 -1.29724]\n",
      "iteration 53000 of 100000; acceptance rate = 0.2569385483292768, current parameters [1.78173 0.366661 -1.10068]\n",
      "iteration 54000 of 100000; acceptance rate = 0.2569396863021055, current parameters [0.607183 0.0498779 -0.785664]\n",
      "iteration 55000 of 100000; acceptance rate = 0.25670442355593537, current parameters [0.893615 -0.238629 -0.687535]\n",
      "iteration 56000 of 100000; acceptance rate = 0.2567989857323976, current parameters [1.02625 -1.48696 0.520124]\n",
      "iteration 57000 of 100000; acceptance rate = 0.2568025122366274, current parameters [0.770313 0.865138 -0.884656]\n",
      "iteration 58000 of 100000; acceptance rate = 0.2567886760573094, current parameters [-0.223209 -1.59976 1.75706]\n",
      "iteration 59000 of 100000; acceptance rate = 0.25686005321943695, current parameters [1.32257 -0.351675 -0.979913]\n",
      "iteration 60000 of 100000; acceptance rate = 0.2573123781270312, current parameters [1.72239 -0.77493 -0.594417]\n",
      "iteration 61000 of 100000; acceptance rate = 0.25727447091031297, current parameters [0.715415 -1.78284 0.918281]\n",
      "iteration 62000 of 100000; acceptance rate = 0.25731843034789764, current parameters [1.21185 -0.338032 -0.791959]\n",
      "iteration 63000 of 100000; acceptance rate = 0.25772606784019303, current parameters [0.515647 -1.48689 0.452936]\n",
      "iteration 64000 of 100000; acceptance rate = 0.25727723004328057, current parameters [0.0783788 -0.553523 -0.104613]\n",
      "iteration 65000 of 100000; acceptance rate = 0.257180658759096, current parameters [0.251712 -0.249921 -0.454543]\n",
      "iteration 66000 of 100000; acceptance rate = 0.25760215754306753, current parameters [1.3003 -0.888782 -0.0405698]\n",
      "iteration 67000 of 100000; acceptance rate = 0.25793644870972077, current parameters [0.875565 0.0442647 -1.11478]\n",
      "iteration 68000 of 100000; acceptance rate = 0.25783444361112334, current parameters [0.753792 -0.555473 -0.380457]\n"
     ]
    }
   ],
   "source": [
    "# Now begin the actual MCMC\n",
    "println(\"Begin MCMC - with step size \", new_step)\n",
    "\n",
    "# reset parameters \n",
    "burnin = 1000\n",
    "max_iter = 100000\n",
    "mcmc = MCMC.MCMCObj(yt_zscore, yt_cov./maximum(yt_cov), priors, \n",
    "                    new_step, u0, max_iter, mcmc_alg, burnin,\n",
    "                    standardized)\n",
    "MCMC.sample_posterior!(mcmc, gpobj, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posterior = MCMC.get_posterior(mcmc)      \n",
    "post_mean = mean(posterior, dims=1)\n",
    "post_cov = cov(posterior, dims=1)\n",
    "println(\"post_mean\")\n",
    "println(post_mean)\n",
    "println(\"post_cov\")\n",
    "println(post_cov)\n",
    "println(\"D util\")\n",
    "println(det(inv(post_cov)))\n",
    "println(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the posteriors together with the priors and the true \n",
    "# parameter values\n",
    "using StatsPlots; \n",
    "\n",
    "true_values = [N0_true θ_true k_true]\n",
    "n_params = length(true_values)\n",
    "\n",
    "for idx in 1:n_params\n",
    "    if idx == 1\n",
    "        param = \"N0\"\n",
    "        xs = collect(0:1:4000)\n",
    "    elseif idx == 2\n",
    "        param = \"Theta\"\n",
    "        xs = collect(0:0.01:12.0)\n",
    "    elseif idx == 3\n",
    "        param = \"k\"\n",
    "        xs = collect(0:0.001:6.0)\n",
    "    else\n",
    "        throw(\"not implemented\")\n",
    "    end\n",
    "\n",
    "    label = \"true \" * param\n",
    "    histogram(posterior[:, idx] .* param_std[idx] .+ param_mean[idx], \n",
    "              bins=100, normed=true, fill=:slategray, lab=\"posterior\")\n",
    "    plot!(xs, mcmc.prior[idx], w=2.6, color=:blue, lab=\"prior\")\n",
    "    plot!([true_values[idx]], seriestype=\"vline\", w=2.6, lab=label)\n",
    "\n",
    "    title!(param)\n",
    "    StatsPlots.savefig(\"posterior_\"*param*\".png\")\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
