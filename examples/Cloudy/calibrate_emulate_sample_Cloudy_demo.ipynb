{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  \n",
    "## Calibrate-Emulate-Sample Demo: Application to a Cloud Microphysics Toy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how parameters of cloud droplet size distributions can be learned from data generated by Cloudy, a cloud microphysics toy model that can be downloaded here: https://github.com/climate-machine/Cloudy.jl. \n",
    "\n",
    "Cloudy takes the following input:\n",
    "* parameters defining a **cloud droplet size distribution** (e.g., parameters defining a gamma distribution or an exponential distribution)\n",
    "* a **''kernel''** defining the efficiency with which cloud droplets collide and coalesce (i.e., stick together and form bigger droplets). \n",
    "\n",
    "Cloudy then simulates how the cloud droplet size distribution evolves over time as a result of the droplet interactions defined by the given kernel. It does so by computing a (user-defined) number of moments of the distribution and propagating them forward in time. The simulation stops after a user-defined amount of time $T$. \n",
    "Treating the kernel as given, Cloudy can be viewed as a function $G(u): \\mathbb{R}^p \\rightarrow \\mathbb{R}^d$ that maps the vector of parameters describing the initial droplet distribution, $u = [u_1, u_2, \\ldots, u_p]$, to a vector of moments, $M = [M_0^T, M_1^T, \\ldots, M_d^T]$\n",
    "\n",
    "The model equation assumes that we have observations $y$ of the moments coming from some observing system, and that these observations are corrupted by additive noise $\\eta$ such that\n",
    "\\begin{equation}\n",
    "    y = G(u) + \\eta,\n",
    "\\end{equation}\n",
    "\n",
    "where the noise $\\eta$ is drawn from a d-dimensional Gaussian with distribution $N(0, \\Gamma_y)$.\n",
    "\n",
    "In this demo, we test the calibrate-emulate-sample framework in a **''perfect-model'' setting**, which means that the observations $y$ do not come from some external observing system but are generated by running Cloudy with the  parameters set to their ''true'' values. \n",
    "\n",
    "**Given knowledge of the artificial observations $y$, the forward model $G: \\mathbb{R}^p \\rightarrow \\mathbb{R}^d$, and some information about the noise level such as its size or distribution (but not its value), the inverse problem we want to solve is to find the unknown parameters $u$.**\n",
    "\n",
    "A comprehensive treatment of the calibrate-emulate-sample approach to Bayesian inverse problems can be found in Cleary et al., 2020: https://arxiv.org/pdf/2001.03689.pdf\n",
    "\n",
    "In a one-sentence summary, the **calibrate** step of the algorithm consists of an Ensemble Kalman Inversion that is used to find good training points for a Gaussian process regression, which in turn is used as a replacement (**emulator**) of the original forward model $G$ in the subsequent Markov chain Monte Carlo **sampling** of the posterior distributions of the unknown parameters.\n",
    "\n",
    "**Final remarks**: Calibrate-emulate-sample was developed to solve inverse problems in situations when running the forward model $G$ is computationally expensive. Cloudy is very cheap to run and it would be computationally feasible to skip the ''calibrate'' and ''emulate'' steps, but this being a demo, we will walk the user through the full pipeline. Applying the full pipeline may also improve the result even when it's not necessary for computational reasons, e.g., because the Gaussian process regression smooths the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cloudy_model.jpg\" alt=\"Cloudy\" style=\"width:600px\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Cloudy modules\n",
    "using Cloudy.ParticleDistributions\n",
    "using Cloudy.KernelTensors\n",
    "using Cloudy.Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "using Distributions  # probability distributions and associated functions \n",
    "using StatsBase\n",
    "using LinearAlgebra\n",
    "using StatsPlots\n",
    "using GaussianProcesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Calibrate-Emulate-Sample modules (adjust paths \n",
    "# if necessary)\n",
    "include(\"CalibrateEmulateSample.jl/src/EKI.jl\")\n",
    "include(\"CalibrateEmulateSample.jl/src/Observations.jl\")\n",
    "include(\"CalibrateEmulateSample.jl/src/GPEmulator.jl\")\n",
    "include(\"CalibrateEmulateSample.jl/src/MCMC.jl\")\n",
    "include(\"CalibrateEmulateSample.jl/src/GModel.jl\")\n",
    "include(\"CalibrateEmulateSample.jl/src/Utilities.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the parameters that we want to learn\n",
    "# We assume that the true particle mass distribution is a \n",
    "# Gamma distribution with parameters N0_true, θ_true, k_true\n",
    "param_names = [\"N0\", \"θ\", \"k\"]\n",
    "n_param = length(param_names)\n",
    "\n",
    "# Define the data from which we want to learn these parameters\n",
    "data_names = [\"M0\", \"M1\", \"M2\"]\n",
    "moments = [0.0, 1.0, 2.0]\n",
    "n_moments = length(moments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assume lognormal priors for all three parameters\n",
    "# Note: For the model G (=Cloudy) to run, N0 needs to be \n",
    "# nonnegative, and θ and k need to be positive. \n",
    "# The EKI update can result in violations of these constraints - \n",
    "# therefore, we perform CES in log space, i.e., we try to find \n",
    "# the logarithms of the true parameters (and of course, the actual\n",
    "# parameters could then simply be obtained by exponentiating the \n",
    "# final results). \n",
    "\n",
    "function logmean_and_logstd(μ, σ)\n",
    "    σ_log = sqrt(log(1.0 + σ^2/μ^2))\n",
    "    μ_log = log(μ / (sqrt(1.0 + σ^2/μ^2)))\n",
    "    return μ_log, σ_log\n",
    "end\n",
    "\n",
    "N0_true = 300.0 \n",
    "θ_true = 1.5597  \n",
    "k_true = 0.0817                  \n",
    "params_true = [N0_true, θ_true, k_true]\n",
    "# Note that dist_true has to be a Cloudy distribution, not a \n",
    "# \"regular\" Julia distribution\n",
    "dist_true = ParticleDistributions.Gamma(N0_true, θ_true, k_true)\n",
    "\n",
    "logmean_N0, logstd_N0 = logmean_and_logstd(280., 40.)\n",
    "logmean_θ, logstd_θ = logmean_and_logstd(3.0, 1.5)\n",
    "logmean_k, logstd_k = logmean_and_logstd(0.5, 0.5)\n",
    "\n",
    "priors = [Distributions.Normal(logmean_N0, logstd_N0),  # prior on N0\n",
    "          Distributions.Normal(logmean_θ, logstd_θ),    # prior on θ\n",
    "          Distributions.Normal(logmean_k, logstd_k)]    # prior on k "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloudy settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Collision-coalescence kernel to be used in Cloudy\n",
    "coalescence_coeff = 1/3.14/4\n",
    "kernel_func = x -> coalescence_coeff\n",
    "kernel = CoalescenceTensor(kernel_func, 0, 100.0)\n",
    "\n",
    "# Time period over which to run Cloudy\n",
    "tspan = (0., 0.5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate (artificial) truth samples\n",
    "g_settings_true = GModel.GSettings(kernel, dist_true, moments, tspan)\n",
    "yt = GModel.run_G(params_true, g_settings_true, \n",
    "                  ParticleDistributions.update_params, \n",
    "                  ParticleDistributions.moment,\n",
    "                  Sources.get_int_coalescence)\n",
    "n_samples = 100\n",
    "samples = zeros(n_samples, length(yt))\n",
    "noise_level = 0.05\n",
    "Γy = noise_level^2 * convert(Array, Diagonal(yt))\n",
    "μ = zeros(length(yt))\n",
    "\n",
    "# Add noise\n",
    "for i in 1:n_samples\n",
    "    samples[i, :] = yt + noise_level^2 * rand(MvNormal(μ, Γy))\n",
    "end\n",
    "\n",
    "truth = Observations.Obs(samples, Γy, data_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrate: Ensemble Kalman Inversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_transform(a::AbstractArray) = log.(a)\n",
    "exp_transform(a::AbstractArray) = exp.(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_ens = 50 # number of ensemble members\n",
    "N_iter = 5 # number of EKI iterations\n",
    "# initial parameters: N_ens x N_params\n",
    "initial_params = EKI.construct_initial_ensemble(N_ens, priors; rng_seed=6)\n",
    "ekiobj = EKI.EKIObj(initial_params, \n",
    "                    param_names, truth.mean, truth.cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize a ParticleDistribution with dummy parameters\n",
    "# The parameters will then be set in run_cloudy_ensemble\n",
    "dummy = 1.0\n",
    "dist_type = ParticleDistributions.Gamma(dummy, dummy, dummy)\n",
    "g_settings = GModel.GSettings(kernel, dist_type, moments, tspan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EKI iterations\n",
    "for i in 1:N_iter\n",
    "    # Note that the parameters are exp-transformed for use as input\n",
    "    # to Clouedy\n",
    "    params_i = deepcopy(exp_transform(ekiobj.u[end]))\n",
    "    g_ens = GModel.run_G_ensemble(params_i, \n",
    "                                  g_settings,\n",
    "                                  ParticleDistributions.update_params,\n",
    "                                  ParticleDistributions.moment,\n",
    "                                  Sources.get_int_coalescence)\n",
    "    EKI.update_ensemble!(ekiobj, g_ens) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EKI results: Has the ensemble collapsed toward the truth?\n",
    "println(\"True parameters: \")\n",
    "println(params_true)\n",
    "\n",
    "println(\"\\nEKI results:\")\n",
    "println(mean(deepcopy(exp_transform(ekiobj.u[end])), dims=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulate: Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gppackage = GPEmulator.GPJL()\n",
    "pred_type = GPEmulator.YType()\n",
    "# Construct kernel:\n",
    "# Sum kernel consisting of Matern 5/2 ARD kernel, a Squared\n",
    "# Exponential Iso kernel and white noise\n",
    "# Note that the kernels take the signal standard deviations on a \n",
    "# log scale as input.\n",
    "len1 = 1.0\n",
    "kern1 = SE(len1, 1.0)\n",
    "len2 = zeros(3)\n",
    "kern2 = Mat52Ard(len2, 0.0)\n",
    "# regularize with white noise\n",
    "white = Noise(log(2.0))\n",
    "# construct kernel\n",
    "GPkernel =  kern1 + kern2 + white\n",
    "    \n",
    "u_tp, g_tp = Utilities.extract_GP_tp(ekiobj, N_iter)\n",
    "normalized = true\n",
    "gpobj = GPEmulator.GPObj(u_tp, g_tp, gppackage; GPkernel=GPkernel, \n",
    "                         normalized=normalized, prediction_type=pred_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check how well the Gaussian Process regression predicts on the\n",
    "# true parameters\n",
    "y_mean, y_var = GPEmulator.predict(gpobj, reshape(log.(params_true), 1, :))\n",
    "\n",
    "println(\"GP prediction on true parameters: \")\n",
    "println(vec(y_mean))\n",
    "println(\"true data: \")\n",
    "println(truth.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample: Markov chain Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initial values\n",
    "u0 = vec(mean(u_tp, dims=1))\n",
    "println(\"initial parameters: \", u0)\n",
    "\n",
    "# MCMC parameters    \n",
    "mcmc_alg = \"rwm\" # random walk Metropolis\n",
    "\n",
    "# First let's run a short chain to determine a good step size\n",
    "burnin = 0\n",
    "step = 0.1 # first guess\n",
    "max_iter = 5000\n",
    "yt_sample = truth.mean\n",
    "mcmc_test = MCMC.MCMCObj(yt_sample, truth.cov, \n",
    "                         priors, step, u0, \n",
    "                         max_iter, mcmc_alg, burnin)\n",
    "new_step = MCMC.find_mcmc_step!(mcmc_test, gpobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now begin the actual MCMC\n",
    "println(\"Begin MCMC - with step size \", new_step)\n",
    "u0 = vec(mean(u_tp, dims=1))\n",
    "\n",
    "# reset parameters \n",
    "burnin = 1000\n",
    "max_iter = 500000\n",
    "\n",
    "mcmc = MCMC.MCMCObj(yt_sample, truth.cov, priors, \n",
    "                    new_step, u0, max_iter, mcmc_alg, burnin)\n",
    "MCMC.sample_posterior!(mcmc, gpobj, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posterior = MCMC.get_posterior(mcmc)      \n",
    "\n",
    "post_mean = mean(posterior, dims=1)\n",
    "post_cov = cov(posterior, dims=1)\n",
    "println(\"post_mean\")\n",
    "println(post_mean)\n",
    "println(\"post_cov\")\n",
    "println(post_cov)\n",
    "println(\"D util\")\n",
    "println(det(inv(post_cov)))\n",
    "println(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the posteriors together with the priors and the true \n",
    "# parameter values\n",
    "using StatsPlots; \n",
    "\n",
    "true_values = [log(N0_true) log(θ_true) log(k_true)]\n",
    "n_params = length(true_values)\n",
    "\n",
    "for idx in 1:n_params\n",
    "    if idx == 1\n",
    "        param = \"N0\"\n",
    "        xs = collect(4.5:0.01:6.5)\n",
    "    elseif idx == 2\n",
    "        param = \"Theta\"\n",
    "        xs = collect(-1.0:0.01:2.5)\n",
    "    elseif idx == 3\n",
    "        param = \"k\"\n",
    "        xs = collect(-4.0:0.01:1.0)\n",
    "    else\n",
    "        throw(\"not implemented\")\n",
    "    end\n",
    "\n",
    "    label = \"true \" * param\n",
    "    histogram(posterior[:, idx], bins=100, normed=true, \n",
    "              fill=:slategray, lab=\"posterior\")\n",
    "    plot!(xs, mcmc.prior[idx], w=2.6, color=:blue, lab=\"prior\")\n",
    "    plot!([true_values[idx]], seriestype=\"vline\", w=2.6, lab=label)\n",
    "\n",
    "    title!(param)\n",
    "    StatsPlots.savefig(\"/home/melanie/Desktop/posterior_\"*param*\".png\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
